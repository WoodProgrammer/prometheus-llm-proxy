'''
    query = ""
    if request.method == "GET":
        query = request.query_params.get("query", "")
    elif request.method == "POST":
        content_type = request.headers.get("content-type", "")
        if "application/x-www-form-urlencoded" in content_type:
            body = await request.body()
            from urllib.parse import parse_qs
            parsed = parse_qs(body.decode())
            query = parsed.get("query", [""])[0]
    
    print("The query is ", query)
    params = dict(request.query_params)

    if "llm_dashboard_metric" in query:
        match = re.search(r'llm_dashboard_metric\{query="([^"]+)"\}', query)
        print("The match result is ", match)
        if match:
            natural_query = match.group(1)
            print("ðŸ”¥ Intercepted natural query:", natural_query)

            # LLM'e gÃ¶nder
            async with httpx.AsyncClient() as client:
                llm_response = await client.post(
                    "http://localhost:11434/api/generate",
                    json={"prompt": f"""
                          Generate promql for this content: '{natural_query}' please only return the query 
                          Only return the query. No explanation, no markdown, no quotes.
                          """,
                          "stream": False, "model": "mistral"},
                    timeout=10.0
                )
                promql = extract_promql(llm_response.json()["response"])
                print("The promql is ", promql)
'''